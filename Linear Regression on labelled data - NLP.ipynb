{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "In this Notebook we will apply Linear Regression on Reviews dataset to predict wheather its a positive or negative comment.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are importing libraries which we'll use \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "source": [
    "## About Dataset\n",
    "\n",
    "Downloaded the data set from the Sentiment Labelled Sentences Data Set from the UCI Machine Learning Repository\n",
    "https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "\n",
    "This data set includes labeled reviews from IMDb, Amazon, and Yelp. Each review is marked with a score of 0 for a negative sentiment or 1 for a positive sentiment.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Reading Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of reviews_dataset in this dataset : 2748\nTotal number of attributes in this dataset : 3\nyelp      1000\namazon    1000\nimdb       748\nName: source, dtype: int64\nTotal number of reviews_dataset under yelp is 1000\nTotal number of reviews_dataset under amazon is 1000\nTotal number of reviews_dataset under imdb is 748\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                            sentence  label source\n",
       "0                           Wow... Loved this place.      1   yelp\n",
       "1                                 Crust is not good.      0   yelp\n",
       "2          Not tasty and the texture was just nasty.      0   yelp\n",
       "3  Stopped by during the late May bank holiday of...      1   yelp\n",
       "4  The selection on the menu was great and so wer...      1   yelp"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wow... Loved this place.</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Crust is not good.</td>\n      <td>0</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Not tasty and the texture was just nasty.</td>\n      <td>0</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stopped by during the late May bank holiday of...</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The selection on the menu was great and so wer...</td>\n      <td>1</td>\n      <td>yelp</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "filepath_dict = {'yelp':   r'F:\\Machine Learning\\NLP\\Sentimental analysis\\Dataset\\\\yelp_labelled.txt',\n",
    "                 'amazon': r'F:\\Machine Learning\\NLP\\Sentimental analysis\\Dataset\\\\amazon_cells_labelled.txt',\n",
    "                 'imdb':   r'F:\\Machine Learning\\NLP\\Sentimental analysis\\Dataset\\\\imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "\n",
    "reviews_dataset = pd.concat(df_list)\n",
    "print(\"Total number of reviews_dataset in this dataset :\",reviews_dataset.shape[0])\n",
    "print(\"Total number of attributes in this dataset :\",reviews_dataset.shape[1])\n",
    "individual_review_counts = reviews_dataset.source.value_counts()\n",
    "print(individual_review_counts)\n",
    "for val,count in zip(individual_review_counts.index, individual_review_counts):\n",
    "    print(\"Total number of reviews_dataset under {} is {}\".format(val,count))\n",
    "reviews_dataset.head(5)"
   ]
  },
  {
   "source": [
    "Now we'll define the functions which we will use to further in this notebook"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(reviews,labels):\n",
    "#     reviews_train, reviews_test, labels_train,labels_test = train_test_split(\n",
    "#         reviews,labels, test_size = 0.25, random_state = 100 )\n",
    "#     return reviews_train, reviews_test, labels_train,labels_test\n",
    "\n",
    "def generate_BOW(reviews_train, reviews_test):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(reviews_train)\n",
    "\n",
    "    reviews_train = vectorizer.transform(reviews_train)\n",
    "    reviews_test = vectorizer.transform(reviews_test)\n",
    "    \n",
    "    return reviews_train,reviews_test\n",
    "\n",
    "def train_linear_regression(reviews_train, labels_train):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(reviews_train, labels_train)\n",
    "\n",
    "    return classifier\n",
    "\n",
    "def calculate_accuracy(classifier,reviews_test,labels_test):\n",
    "    score = classifier.score(reviews_test,labels_test)\n",
    "    return score\n",
    "\n",
    "def run(reviews,labels, source = \"compllete\"):\n",
    "    reviews_train, reviews_test, labels_train,labels_test = train_test_split(\n",
    "        reviews,labels, test_size=0.25, random_state=1000 )\n",
    "\n",
    "    reviews_train,reviews_test = generate_BOW(reviews_train,reviews_test)\n",
    "    classifier = train_linear_regression(reviews_train,labels_train)\n",
    "    score = calculate_accuracy(classifier, reviews_test,labels_test)\n",
    "    print(\"Accuracy for {} dataset is {:.3f}\".format(source,score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for yelp dataset is 0.796\n",
      "Accuracy for amazon dataset is 0.796\n",
      "Accuracy for imdb dataset is 0.749\n"
     ]
    }
   ],
   "source": [
    "for source in reviews_dataset['source'].unique():\n",
    "    df_source = reviews_dataset[reviews_dataset['source'] == source]\n",
    "    reviews = df_source['sentence'].values\n",
    "    labels = df_source['label'].values\n",
    "    run(reviews,labels,source = source)"
   ]
  },
  {
   "source": [
    "In above cells we have train the model for individual sources now we'll train it for all the sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for compllete dataset is 0.820\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews_dataset[\"sentence\"].values\n",
    "labels = reviews_dataset[\"label\"].values\n",
    "run(reviews,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}